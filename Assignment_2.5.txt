1. Explain what is a cluster and what is a hadoop cluster

Hadoop Cluster:

*Generally any set of loosely coupled or tightly coupled systems that work together as a single system is called as cluster.
*Cluster which is used for Hadoop is known as Hadoop Cluster.
*Hadoop cluster is a special type of computational cluster designed for storing and analyzing vast amount of unstructured data 
in distributed computing environment.
*These clusters run on low cost commodity  hardware.
*They are most commonly referred as shared nothing systems because the only thing that is shared between the nodes is the
network that links them together.
*Hadoop cluster consists of 3 components
1.Client
2.Master
3.Slave

Client:
* It is neither master nor slave, rather play the role of loading the data into the cluster.
*submits the MapReduce jobs describing how the data should be processed and retrieved after completion of job.

Master:
*It consists of 3 components such as NameNode, Secondary NameNode and JobTracker.
*NameNode: It doesnt store any files but only the file's meta data.
*Secondary NameNode: It is not the back up or replica of the NameNode. The job of the Secondary NameNode is to contact
NameNode periodically. Suppose if the NameNode crashes, the Secondary NameNode contacts the NameNode and pulls
the copy of metadata information out of NameNode.
*Slaves: They are the majority of machines in Hadoop cluster and are responsible to store the data and process. Each slave runs both DataNode and TaskTracker daemon
which communicates to their masters.


2. Explain the components of Hadoop 1.x

*The major components are HDFS and MapReduce.
*They are known as pillars of Hadoop 1.x.
*Hadoop system is a master/slave architecture.
*Hadoop 1.x file system has 64MB block size.
*The default replication factor is 3 which is configurable.
*There are total 5 components 
                   1. NameNode
                   2.DataNode
                   3.Secondary NameNode
                   4.JobTracker
                   5.TaskTracker

*NameNode, DataNode and Secondary NameNode are called as storage components.
*JobTracker and TaskTracker are called as processing components.

NameNode:
*The job of the NameNode is to decide how to store the physical location of each and evert file in blocks of the clusters.
*It also manages the metadata of the files stored.
*NameNode always stores metadata in FSImage and EditLogs file periodically. This process is called as Checkpoint mechanism.

DataNode:
*DataNode stores the file data in blocks.
*It sends the RPC signal periodically to notify the NameNode that it is alive and working.

Secondary NameNode:
*It acts as the backbone of the NameNode.
*It stores the metadata details from NameNode periodically as per chechpoint mechanism.
*When the NameNode goes down, the Secondary NameNode comes into action and acts as the temporary NameNode till the NameNode
becomes active again.

JobTracker:
*It resides in the same node as of NameNode.
*Its job is to assign jobs to the DataNodes or TaskTrackers.
*It also decides the job scheduling for the DataNodes or TaskTrakers.
*In case of failure, it decides about the rescheduling of the task to some other nodes. 

TaskTracker:
*Its job is to execute the task assigned by the JobTracker.
